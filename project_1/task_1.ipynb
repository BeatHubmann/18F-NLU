{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Description-Task-1:-RNN-Language-Modelling-(30-+10-Points)\" data-toc-modified-id=\"Description-Task-1:-RNN-Language-Modelling-(30-+10-Points)-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Description Task 1: RNN Language Modelling (30 +10 Points)</a></span><ul class=\"toc-item\"><li><span><a href=\"#1a)-Language-Modelling-(30-Points)\" data-toc-modified-id=\"1a)-Language-Modelling-(30-Points)-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>1a) Language Modelling (30 Points)</a></span></li><li><span><a href=\"#Conditional-Generation-(10-Points)\" data-toc-modified-id=\"Conditional-Generation-(10-Points)-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Conditional Generation (10 Points)</a></span></li></ul></li><li><span><a href=\"#Code-for-Task-1\" data-toc-modified-id=\"Code-for-Task-1-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Code for Task 1</a></span><ul class=\"toc-item\"><li><span><a href=\"#Task-1.1\" data-toc-modified-id=\"Task-1.1-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Task 1.1</a></span><ul class=\"toc-item\"><li><span><a href=\"#Setup-and-preparation\" data-toc-modified-id=\"Setup-and-preparation-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Setup and preparation</a></span></li><li><span><a href=\"#Data-preprocessing\" data-toc-modified-id=\"Data-preprocessing-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Data preprocessing</a></span></li><li><span><a href=\"#RNN-construction\" data-toc-modified-id=\"RNN-construction-2.1.3\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>RNN construction</a></span></li><li><span><a href=\"#Training\" data-toc-modified-id=\"Training-2.1.4\"><span class=\"toc-item-num\">2.1.4&nbsp;&nbsp;</span>Training</a></span></li><li><span><a href=\"#Sample-and-test\" data-toc-modified-id=\"Sample-and-test-2.1.5\"><span class=\"toc-item-num\">2.1.5&nbsp;&nbsp;</span>Sample and test</a></span></li><li><span><a href=\"#Output\" data-toc-modified-id=\"Output-2.1.6\"><span class=\"toc-item-num\">2.1.6&nbsp;&nbsp;</span>Output</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Understanding: Project 1\n",
    "\n",
    "[__Natural Language Understanding, Spring 2018, ETHZ__](http://www.da.inf.ethz.ch/teaching/2018/NLU/)\n",
    "\n",
    "[__Project 1__ (ETHZ network)](http://www.da.inf.ethz.ch/teaching/2018/NLU/material/project.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project to-do list:\n",
    "\n",
    "Somewhat in order of importance:\n",
    "\n",
    "- change code to unroll RNN in time instead of using dynamic_rnn\n",
    "- make sure the target data fed into the crossentropy metric is really in correct form\n",
    "- try own implementation of basic RNN cell instead of TF-prefab RNN or LSTM cell\n",
    "- (Done 2.4.2018): change implementation to use the Xavier initializer instead of the uniform distribution currently used (see below)\n",
    "- (Done 2.4.2018): change all `tf.Variable` variable inits to the better practice form like `W = tf.get_variable(name='example', shape=[784, 256], initializer=tf.contrib.layers.xavier_initializer())` which also includes the proper weight init\n",
    "- include dropout at input and/or RNN cell level for regularization\n",
    "- clean up namespaces, tensor naming\n",
    "- (Started 2.4.2018, but TBC) build in all reporting for Tensorboard\n",
    "- implement perplexity function\n",
    "- adapt code to allow for differently sized timesteps\n",
    "- make arrangements to save trained model\n",
    "- adapt code to allow for use of pretrained word2vec embedding\n",
    "- implement result output function\n",
    "- implement sampling function for conditional text generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description Task 1: RNN Language Modelling (30 +10 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a) Language Modelling (30 Points)\n",
    "Your task is to build a simple LSTM language model. To be precise, we assume that words are independent given the recurrent hidden state; we compute a new hidden state given the last hidden state and last word, and predict the next word given the hidden state:\n",
    "$$ P(w_1,\\dots,w_n) = 􏰀\\prod_{t=1}^{n}P(w_t|\\mathbf{h}_t)$$\n",
    "$$ P(w_t|\\mathbf{h}_t) = \\text{softmax}(\\mathbf{Wh}_t)$$\n",
    "$$ \\mathbf{h}_t = f(\\mathbf{h}_{t−1}, w_{t-1}^{*})$$\n",
    "\n",
    "where $f$ is the LSTM recurrent function, $\\mathbf{W} \\in \\mathbb{R}^{|V|×d}$ are softmax weights and $\\mathbf{h_0}$ is either an all-zero constant or a trainable parameter.\n",
    "You can use the tensorflow cell implementation __[1](https://www.tensorflow.org/api_docs/python/tf/nn/rnn_cell)__ to carry out the recurrent computation in $f$. However, you must construct the actual RNN yourself (e.g. don’t use tensorflow’s `static_rnn` or `dynamic_rnn` or any other RNN library). That means, you will need to use a python loop that sets up the unrolled graph. To make your life simpler, please follow these design choices:\n",
    "\n",
    "__Model and Data specification__\n",
    "\n",
    "- Use a special sentence-beginning symbol `<bos>` and a sentence-end symbol `<eos>` (please use exactly these, including brackets). The `<bos>` symbol is the input, when predicting the first word and the `<eos>` symbol you require your model to predict at the end of every sentence.\n",
    "- Use a maximum sentence length of 30 (including the `<bos>` and `<eos>` symbol). Ignore longer sentences during training and testing.\n",
    "- Use a special padding symbol `<pad>` (please use exactly this, including brackets) to fill up sentences of length shorter than 30. This way, all your input will have the same size.\n",
    "- Use a vocabulary consisting of the 20K most frequent words in the training set, including the symbols `<bos>`, `<eos>`, `<pad>` and `<unk>`. Replace out-of-vocabulary words with the `<unk>` symbol before feeding them into your network (don’t change the file content).\n",
    "- Provide the ground truth last word as input to the RNN, not the last word you predicted. This is common practice.\n",
    "- Language models are usually trained to minimize the cross-entropy. Use tensorflow’s `tf.nn.sparse_softmax_cross_entropy_with_logits` to compute the loss (*This operation fuses the computation of the soft-max and the cross entropy loss given the logits. For numerical stability, it’s very important to use this function.*). Use the AdamOptimizer with default parameters to minimize the loss. Use `tf.clip_by_global_norm` to clip the norm of the gradients to 5.\n",
    "- Use a batch size of 64.\n",
    "- Use the data at __[6](https://polybox.ethz.ch/index.php/s/qUc2NvUh2eONfEB)__. Don’t pre-process the input further. All the data is already white-space tokenized and\n",
    "lower-cased. One sentence per line.\n",
    "- To initialize your weight matrices, use the `tf.contrib.layers.xavier_initializer()` initializer introduced in __[5](http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf)__.\n",
    "\n",
    "__Experiments__\n",
    "All experiments should not run for longer than, say, four hours on the GPU. For this task, your\n",
    "grade won’t improve with performance.\n",
    "\n",
    "- __Experiment A__: Train your model with word-embedding dimensionality of 100 and a hidden state size of 512 and compute sentence perplexity on the evaluation set (see submission format below).\n",
    "- __Experiment B__: It is common practice, to pretrain word embeddings using e.g. `word2vec`. This should make your model train faster as words will come already with some useful representation. Use the code at __[3](http://da.inf.ethz.ch/teaching/2018/NLU/material/load_embeddings.py)__ to load these word embeddings __[4](https://polybox.ethz.ch/index.php/s/cpicEJeC2G4tq9U)__ trained on the same corpus. Train your model again and compute evaluation perplexity.\n",
    "- __Experiment C__: It is often desirable to make the LSTM more powerful, by increasing the hidden dimensionality. However, this will naturally increase the parameters $\\mathbf{W}$ of the softmax. As a compromise, one can use a larger hidden state, but down-project it before the softmax. Increase the hidden state dimensionality from 512 to 1024, but down-project $h_t$ to dimensionality 512 before predicting $w_t$ as in\n",
    "$$ \\mathbf{\\tilde{h}}_t = \\mathbf{W}_P\\mathbf{h}_t$$\n",
    "where $W_P$ are parameters. Train your model again and compute evaluation perplexity.\n",
    "\n",
    "__Submission and grading__\n",
    "- Grading scheme: 100% correctness.\n",
    "- Deadline April 20th, 23:59:59.\n",
    "- You are not allowed to copy-paste any larger code blocks from existing implementations.\n",
    "- Hand in\n",
    "    - Your python code\n",
    "    - __Three__ result files containing sentence-level perplexity numbers on the __test__ set (to be distributed) for\n",
    "all three experiments. Recall that perplexity of a sentence $S = ⟨w_1, \\dots , w_n⟩$ with respect to your model $p(w_t|w_1, \\dots, w_{t−1})$ is defined as\n",
    "$$ \\text{Perp} = 2^{-\\frac{1}{n} \\sum_{t=1}^{n}\\log_2 p(w_t|w_1,\\dots,w_{t−1})}$$\n",
    "The `<eos>` symbol is part of the sequence, while the `<pad>` symbols (if any) are not. Be sure to have the basis of the exponential and the logarithm match.<br>\n",
    "__Input format sentences.test__<br>\n",
    "One sentence (none of them is longer than 28 tokens) per line:<br>\n",
    "         ```beside her , jamie bounced on his seat .\n",
    "         i looked and saw claire montgomery looking up at me .\n",
    "         people might not know who alex was , but they knew to listen to him .```<br>\n",
    "__Required output format groupXX.perplexityY__<br>\n",
    "(where XX is your group __number__ and Y ∈ {A,B,C} is the experiment). One perplexity number per line:<br>\n",
    "         $10.232$<br>\n",
    "         $2.434$<br>\n",
    "         $5.232$<br>\n",
    "Make sure to have equally many lines in the output as there are in the input – otherwise your submission will be rejected automatically.\n",
    "    - You have to submit at https://cmt3.research.microsoft.com/NLUETHZ2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Generation (10 Points)\n",
    "Let’s use your trained language model from above to generate sentences. Given an initial sequence of words, your are asked to __greedily__ generate words until either your model decides to finish the sentence (it generated `<eos>`) or a given maximum length has been reached. Note, that this task does not involve any training. Please see the tensorflow documentation on how to save and restore your model from above.\n",
    "There are several ways how to implement the generation. For example, you can define a graph that computes just one step of the RNN given the last input and the last state (both from a new placeholder).\n",
    "$$ \\text{state}_t, p_t = f(\\text{state}_{t−1},w_{t−1}) $$\n",
    "That means, for a prefix of size $m$ and a desired length of $n$, you run this graph $n$ times. The first $m + 1$ times you take the input form the prefix. For the rest of the sequence, you take the most likely2 word $w^{t−1} = \\text{argmax}_w p_{t−1}(w)$ from the last step.\n",
    "\n",
    "- Grading scheme: 100% correctness.\n",
    "- Deadline April 20th, 23:59:59.\n",
    "- You are not allowed to copy-paste any larger code blocks from existing implementations.\n",
    "- Hand in\n",
    "    - Your python code\n",
    "    - Your continued sentences of length up to 20. Use your trained model from experiment __C__ in task 1.1.\n",
    "    __Input format sentences.continuation__ One sentence (of length less than 20) per line:<br>\n",
    "         ```beside her ,\n",
    "         i\n",
    "         people might not know```<br>\n",
    "    The `<bos>` symbol is not explicitly in the file, but you should still use it as the first input.<br>\n",
    "    __Required output format groupXX.continuation__ (where XX is your __group number__)<br>\n",
    "         ```beside her , something happened ! <eos>\n",
    "         i do n’t recall making a noise , but i must have , because bob just looked up from his\n",
    "         people might not know the answer . <eos>```\n",
    "    - You have to submit at https://cmt3.research.microsoft.com/NLUETHZ2018\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-18T06:26:00.314606Z",
     "start_time": "2018-03-18T06:26:00.303743Z"
    }
   },
   "source": [
    "__Infrastructure__\n",
    "\n",
    "You must use Tensorflow, but any programming language is allowed. However, we strongly recommend `python3`. You have access to two compute resources: Unlimited CPU usage on Euler and GPU usage on Leonhard. Note that the difference in speed is typically a factor between 10 and 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for Task 1\n",
    "### Task 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-18T08:22:42.147335Z",
     "start_time": "2018-03-18T08:22:42.144046Z"
    }
   },
   "source": [
    "#### Setup and preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-18T07:22:12.364855Z",
     "start_time": "2018-03-18T07:22:12.360292Z"
    }
   },
   "source": [
    "Make sure you have done the following:\n",
    "\n",
    "- Download data from https://polybox.ethz.ch/index.php/s/qUc2NvUh2eONfEB and unpack into `./data/` subdirectory\n",
    "- Download embeddings from https://polybox.ethz.ch/index.php/s/cpicEJeC2G4tq9U and unpack into `./data/` subdirectory\n",
    "- Download helper function from http://da.inf.ethz.ch/teaching/2018/NLU/material/load_embeddings.py and put into `./helpers/` subdirectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-19T20:59:33.773331Z",
     "start_time": "2018-03-19T20:59:24.288656Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "#import tqdm\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter \n",
    "from helpers.load_embeddings import load_embedding\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-19T20:59:34.058780Z",
     "start_time": "2018-03-19T20:59:33.776668Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read training and evalutation data from files\n",
    "\n",
    "with open('./data/sentences.train', 'r') as f:\n",
    "    train_data = f.read()\n",
    "    \n",
    "with open('./data/sentences.eval', 'r') as f:\n",
    "    eval_data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-19T20:59:34.079802Z",
     "start_time": "2018-03-19T20:59:34.062797Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data sample:\n",
      " ====================\n",
      "`` i 've never had any ice-cream for myself , my father never let me have any . ''\n",
      "`` and even if sh \n",
      " ................................................................................\n",
      "\n",
      " Evaluation data sample:\n",
      " ====================\n",
      "he took my face in his hands and held my face where he wanted it as he kissed me senseless .\n",
      "`` on t \n",
      " ................................................................................\n"
     ]
    }
   ],
   "source": [
    "# Have a peek at the given raw data\n",
    "\n",
    "print('Training data sample:\\n', 20*'=')\n",
    "print(train_data[:100], '\\n', 80*'.')\n",
    "\n",
    "print('\\n Evaluation data sample:\\n', 20*'=')\n",
    "print(eval_data[:100], '\\n', 80*'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-19T21:15:32.925624Z",
     "start_time": "2018-03-19T21:15:17.265318Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sentences:\n",
      " [\"`` i 've never had any ice-cream for myself , my father never let me have any . ''\", \"`` and even if she was , the gargoyle could hardly halt me from harming her . ''\", 'pigafetta repeated the threat , which had no apparent effect .', \"best to barricade oneself , no ? ''\", \"`` why would he lie ? ''\"]\n",
      "Sample words:\n",
      " ['``', 'i', \"'ve\", 'never', 'had', 'any', 'ice-cream', 'for', 'myself', ',', 'my', 'father', 'never', 'let', 'me', 'have', 'any', '.', \"''\", '``']\n",
      "Top frequency words:\n",
      " ['.', ',', 'the', 'i', 'to', 'and', '``', \"''\", 'a', 'he', 'of', 'you', 'was', 'her', 'it', 'she', 'in', 'his', 'that', '?']\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Get sentences from data\n",
    "train_text = ''.join(train_data)\n",
    "train_sentences = train_text.split('\\n')\n",
    "print('Sample sentences:\\n', train_sentences[:5])\n",
    "\n",
    "# Make text contiguous again and break into words for vocabulary\n",
    "words = ' '.join(train_sentences).split()\n",
    "print('Sample words:\\n', words[:20])\n",
    "\n",
    "# Make a word counter\n",
    "counts = Counter(words)\n",
    "vocab = sorted(counts, key=counts.get, reverse=True)\n",
    "print('Top frequency words:\\n', vocab[:20])\n",
    "\n",
    "# Clip word counter to defined length and append special symbol words\n",
    "symbols = ['<bos>', '<eos>', '<pad>', '<unk>']\n",
    "vocab_length = 20000 # restrict to 20k most frequent tokens\n",
    "vocab = vocab[:vocab_length-len(symbols)] # kick out the last 4 to replace w/ symbols\n",
    "for each in symbols:\n",
    "    vocab.append(each)\n",
    "    \n",
    "# Make a vocabulary to convert words to integers\n",
    "vocab_to_int = {word: i for i, word in enumerate(vocab, 0)} # consider start with 1 if problems\n",
    "\n",
    "# Make a vocabulary to get words from integers at the end\n",
    "int_to_vocab = dict(enumerate(vocab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-19T21:16:05.839199Z",
     "start_time": "2018-03-19T21:16:05.669285Z"
    }
   },
   "outputs": [],
   "source": [
    "# Encode training sentences to integers and insert symbol words where necessary\n",
    "\n",
    "### ATTN: Remove next line after finishing, keeping data set small for speedup\n",
    "train_sentences = train_sentences[:1000]\n",
    "\n",
    "max_sentence_length = 30 # Given by task description\n",
    "sentences_ints = []\n",
    "for each in train_sentences:\n",
    "    sentence = each.split()\n",
    "    if len(sentence) < max_sentence_length-2: # -2 to allow for <bos>, <eos>\n",
    "        sentence_int = [vocab_to_int['<bos>']] \n",
    "        sentence_int += [vocab_to_int[word] if word in vocab_to_int\\\n",
    "                             else vocab_to_int['<unk>'] for word in sentence]\n",
    "        sentence_int.append(vocab_to_int['<eos>'])\n",
    "        while len(sentence_int) < max_sentence_length:\n",
    "            sentence_int.append(vocab_to_int['<pad>'])\n",
    "        sentences_ints.append(sentence_int)\n",
    "source = np.array(sentences_ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-19T21:32:25.660853Z",
     "start_time": "2018-03-19T21:32:25.635477Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build batch generator for training    \n",
    "def get_batches(source_arr, batch_size):\n",
    "    '''Generator that returns features x and targets y of size:\n",
    "            batch_size(number of sequences from source_arr)\n",
    "                    x\n",
    "            n_steps (length of sequence from source_arr)\n",
    "    \n",
    "    Inputs\n",
    "    ------\n",
    "    source_arr: A np.ndarray to generate features and targets from\n",
    "    batch_size: An int number of sequences required per batch\n",
    "    \n",
    "    Outputs\n",
    "    -------\n",
    "    x: A np.ndarray of feature sequences according to parameters above\n",
    "    y: A np.ndarray of target sequences according to paramteres above.\n",
    "    '''\n",
    "    # Determine number of sequence steps \n",
    "    n_steps = source_arr.shape[1] # = 30 in this task as we've padded to that length\n",
    "\n",
    "    # Determine number of full batches that can be served\n",
    "    n_batches = source_arr.shape[0] // batch_size\n",
    "    \n",
    "    # Crop source to make full batches only\n",
    "    source_arr = source_arr[:n_batches * batch_size]\n",
    "    \n",
    "    for i in range(0, source_arr.shape[0], batch_size):\n",
    "        # Feature sequence\n",
    "        x = source_arr[i:i+batch_size, :]\n",
    "        # Target sequence: Shift feature sequence by one step, wrap around\n",
    "        y = np.zeros_like(x)\n",
    "        y[:, :-1]= x[:, 1:] # Center part with shift\n",
    "        y[:, -1] = x[:, 0] # Wrap around\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-19T21:16:41.881876Z",
     "start_time": "2018-03-19T21:16:41.872045Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_input_layer(batch_size, num_steps=30):\n",
    "    '''Build placeholders for inputs, targets, dropout factor\n",
    "    \n",
    "        TBC\n",
    "    '''\n",
    "    # Placeholders for inputs, targets and dropout coefficient\n",
    "    with tf.variable_scope(\"input_layer\") as scope:\n",
    "        inputs = tf.placeholder(tf.int32, [batch_size, num_steps], name='inputs')\n",
    "        targets = tf.placeholder(tf.int32, [batch_size, num_steps], name='targets')\n",
    "        keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    \n",
    "    return inputs, targets, keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-19T21:16:59.199901Z",
     "start_time": "2018-03-19T21:16:59.192835Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_embedding_layer(vocab_length, embedding_size, inputs):\n",
    "    '''Build embedding layer as one-hot encoding not viable\n",
    "    \n",
    "        TBC\n",
    "    '''\n",
    "    embedding_matrix = tf.get_variable(name = 'embedding_matrix', shape = [vocab_length, embedding_size], initializer = tf.random_uniform_initializer(-1, 1))\n",
    "    embeddings = tf.nn.embedding_lookup(embedding_matrix, inputs, name='embedding_lookup')\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-19T21:17:16.587124Z",
     "start_time": "2018-03-19T21:17:16.577779Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_lstm_layer(lstm_size, lstm_layers, batch_size, keep_prob):\n",
    "    '''Build LSTM cells\n",
    "    \n",
    "        TBC\n",
    "    '''\n",
    "     \n",
    "    # LSTM cell from library as in task description\n",
    "    cell = tf.nn.rnn_cell.BasicLSTMCell(lstm_size)\n",
    "    \n",
    "    # Fancier cell option with multiple possible layers\n",
    "    # cell = tf.nn.rnn_cell.MultiRNNCell([tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.BasicLSTMCell(lstm_size), output_keep_prob=keep_prob) for _ in range(lstm_layers)])\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "    \n",
    "    return cell, initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-19T21:17:34.137771Z",
     "start_time": "2018-03-19T21:17:34.112939Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_output_layer(lstm_layer_output, lstm_size, out_size):\n",
    "    '''Build softmax output layer and return its output plus logits\n",
    "    \n",
    "        TBC\n",
    "    '''\n",
    "    # Reshape lstm_layer_output: Get one row for e/a step (i.e. over axis 1)\n",
    "    rows_output = tf.concat(lstm_layer_output, 1)\n",
    "    # Reshape again to get tensor with in_size (=size of lstm_layer_output) cols\n",
    "    x = tf.reshape(rows_output, [-1, lstm_size])\n",
    "    \n",
    "    # Hook up LSTM outputs to softmax layer\n",
    "    with tf.variable_scope('softmax') as scope:\n",
    "        # Weight and bias variables: TBC: Project wants some funny initializer here (I think)\n",
    "        xavier_initializer = tf.contrib.layers.xavier_initializer()\n",
    "        softmax_w = tf.get_variable(name = \"softmax_weight\", shape = [lstm_size, out_size], initializer = xavier_initializer)\n",
    "        softmax_b = tf.get_variable(name = \"softmax_bias\", shape = [out_size], initializer =tf.zeros_initializer)\n",
    "    \n",
    "    # Calculate logits from softmax layer\n",
    "    logits = tf.add(tf.matmul(x, softmax_w), softmax_b)\n",
    "    \n",
    "    # Finally, get word probabilities from logits\n",
    "    output = tf.nn.softmax(logits, name='predictions')\n",
    "    \n",
    "    return output, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-19T21:17:51.620680Z",
     "start_time": "2018-03-19T21:17:51.608579Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_loss(logits, targets, lstm_size, out_size):\n",
    "    ''' Calculate the loss from the logits and the targets.\n",
    "    \n",
    "            TBC\n",
    "    '''\n",
    "    # One-hot encode targets:\n",
    "    # THIS IS FISHY, TBC!: We used embedding at the input, so I think\n",
    "    # we should use the same again here for the reverse. However, I made a mess of \n",
    "    # the dimensions and used one-hot as a quick fix to check if the rest of the code\n",
    "    # worked. \n",
    "    y_one_hot = tf.one_hot(targets, out_size)\n",
    "\n",
    "    # Reshape encoded targets to fit logits\n",
    "    y_reshaped = tf.reshape(y_one_hot, logits.get_shape())\n",
    "    \n",
    "    # Softmax cross entropy loss\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y_reshaped)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-19T21:18:11.083460Z",
     "start_time": "2018-03-19T21:18:11.072161Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_optimizer(loss, learning_rate, grad_clip):\n",
    "    ''' Build optmizer for training\n",
    "    \n",
    "        TBC\n",
    "    '''\n",
    "    \n",
    "    # Optimizer for training, using gradient clipping to control exploding gradients\n",
    "    tvars = tf.trainable_variables()\n",
    "    grads, _ = tf.clip_by_global_norm(tf.gradients(loss, tvars), grad_clip)\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate)\n",
    "    optimizer = train_op.apply_gradients(zip(grads, tvars))\n",
    "    \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-19T21:18:32.303665Z",
     "start_time": "2018-03-19T21:18:32.248832Z"
    }
   },
   "outputs": [],
   "source": [
    "class LanguageModel:\n",
    "    def __init__(self, out_size=vocab_length, batch_size=64, num_steps=30,\n",
    "                   lstm_size=512, lstm_layers=1, learning_rate=0.001,\n",
    "                   grad_clip=5, embedding_size=100, keep_prob=0.5):\n",
    "        \n",
    "        # Reset tensorflow graph for clean slate\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        \n",
    "        # Build input layer\n",
    "        self.inputs, self.targets, self.keep_prob = build_input_layer(batch_size,\n",
    "                                                                      num_steps)\n",
    "\n",
    "        # Build embedding layer\n",
    "        embeddings = build_embedding_layer(vocab_length, embedding_size,\n",
    "                                           self.inputs)\n",
    "\n",
    "        # Build LSTM layer\n",
    "        lstm, self.initial_state = build_lstm_layer(lstm_size, lstm_layers,\n",
    "                                                    batch_size, self.keep_prob)\n",
    "\n",
    "        # Unfold RNN: Replace 'dynamic_rnn' below with this once the rest works\n",
    "        # state = initial_state\n",
    "        # outputs = []\n",
    "        # for time_step in range(num_steps):\n",
    "        #     if time_step > 0:\n",
    "        #         tf.get_variable_scope().reuse_variables()\n",
    "        #     lstm_output, state = stacked_lstm(inputs, state)\n",
    "        #     outputs.append(lstm_output)\n",
    "        # state = final_state\n",
    "\n",
    "        # Run data through RNN with dynamic_rnn, NOT FOR FINAL HAND-IN\n",
    "        outputs, self.final_state = tf.nn.dynamic_rnn(lstm, embeddings,\n",
    "                                                      initial_state=self.initial_state)\n",
    "\n",
    "        # Build softmax output layer\n",
    "        self.prediction, self.logits = build_output_layer(outputs, lstm_size, out_size)\n",
    "\n",
    "        # Build loss\n",
    "        self.loss = build_loss(self.logits, self.targets, lstm_size, out_size)\n",
    "\n",
    "        # Build optimizer\n",
    "        self.optimizer = build_optimizer(self.loss, learning_rate, grad_clip)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-19T21:18:53.036595Z",
     "start_time": "2018-03-19T21:18:53.027943Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "\n",
    "embedding_size = 100\n",
    "lstm_size = 512\n",
    "lstm_layers = 1\n",
    "batch_size = 64\n",
    "out_size = vocab_length\n",
    "learning_rate = 0.001\n",
    "keep_prob = 0.5\n",
    "grad_clip = 5.0\n",
    "num_steps = 30\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-19T21:40:05.098136Z",
     "start_time": "2018-03-19T21:32:45.203876Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10\t Training step: 1\t Batch loss: 9.9246\t 4.218139 sec/batch\n",
      "Epoch: 1/10\t Training step: 2\t Batch loss: 9.6482\t 4.405486 sec/batch\n",
      "Epoch: 1/10\t Training step: 3\t Batch loss: 9.2186\t 4.829539 sec/batch\n",
      "Epoch: 1/10\t Training step: 4\t Batch loss: 8.5737\t 4.868984 sec/batch\n",
      "Epoch: 1/10\t Training step: 5\t Batch loss: 7.8536\t 4.526288 sec/batch\n",
      "Epoch: 1/10\t Training step: 6\t Batch loss: 7.2155\t 4.397932 sec/batch\n",
      "Epoch: 1/10\t Training step: 7\t Batch loss: 6.2262\t 4.437476 sec/batch\n",
      "Epoch: 1/10\t Training step: 8\t Batch loss: 5.4345\t 4.547139 sec/batch\n",
      "Epoch: 1/10\t Training step: 9\t Batch loss: 4.8648\t 4.388584 sec/batch\n",
      "Epoch: 1/10\t Training step: 10\t Batch loss: 4.0930\t 5.998131 sec/batch\n",
      "Epoch: 1/10\t Training step: 11\t Batch loss: 3.8794\t 5.337300 sec/batch\n",
      "Epoch: 1/10\t Training step: 12\t Batch loss: 3.4215\t 4.625888 sec/batch\n",
      "Epoch: 1/10\t Training step: 13\t Batch loss: 3.2233\t 5.161476 sec/batch\n",
      "Epoch: 1/10\t Training step: 14\t Batch loss: 3.4536\t 4.820511 sec/batch\n",
      "Epoch: 1/10\t Training step: 15\t Batch loss: 3.6772\t 4.745643 sec/batch\n",
      "Epoch: 2/10\t Training step: 16\t Batch loss: 3.3588\t 3.948663 sec/batch\n",
      "Epoch: 2/10\t Training step: 17\t Batch loss: 3.6222\t 4.035600 sec/batch\n",
      "Epoch: 2/10\t Training step: 18\t Batch loss: 3.3146\t 4.029010 sec/batch\n",
      "Epoch: 2/10\t Training step: 19\t Batch loss: 3.4714\t 4.013843 sec/batch\n",
      "Epoch: 2/10\t Training step: 20\t Batch loss: 3.6753\t 3.676249 sec/batch\n",
      "Epoch: 2/10\t Training step: 21\t Batch loss: 3.7767\t 3.826559 sec/batch\n",
      "Epoch: 2/10\t Training step: 22\t Batch loss: 3.2729\t 3.889896 sec/batch\n",
      "Epoch: 2/10\t Training step: 23\t Batch loss: 3.2709\t 3.685577 sec/batch\n",
      "Epoch: 2/10\t Training step: 24\t Batch loss: 3.4437\t 3.559474 sec/batch\n",
      "Epoch: 2/10\t Training step: 25\t Batch loss: 3.1814\t 3.571996 sec/batch\n",
      "Epoch: 2/10\t Training step: 26\t Batch loss: 3.3675\t 3.615443 sec/batch\n",
      "Epoch: 2/10\t Training step: 27\t Batch loss: 3.1151\t 4.034365 sec/batch\n",
      "Epoch: 2/10\t Training step: 28\t Batch loss: 3.0822\t 3.549903 sec/batch\n",
      "Epoch: 2/10\t Training step: 29\t Batch loss: 3.3084\t 3.594153 sec/batch\n",
      "Epoch: 2/10\t Training step: 30\t Batch loss: 3.4560\t 3.566247 sec/batch\n",
      "Epoch: 3/10\t Training step: 31\t Batch loss: 3.1502\t 3.529660 sec/batch\n",
      "Epoch: 3/10\t Training step: 32\t Batch loss: 3.3414\t 3.580491 sec/batch\n",
      "Epoch: 3/10\t Training step: 33\t Batch loss: 3.0395\t 3.831982 sec/batch\n",
      "Epoch: 3/10\t Training step: 34\t Batch loss: 3.1668\t 3.673826 sec/batch\n",
      "Epoch: 3/10\t Training step: 35\t Batch loss: 3.3474\t 4.352010 sec/batch\n",
      "Epoch: 3/10\t Training step: 36\t Batch loss: 3.4747\t 4.807319 sec/batch\n",
      "Epoch: 3/10\t Training step: 37\t Batch loss: 3.0381\t 4.849974 sec/batch\n",
      "Epoch: 3/10\t Training step: 38\t Batch loss: 3.0734\t 6.910451 sec/batch\n",
      "Epoch: 3/10\t Training step: 39\t Batch loss: 3.2297\t 5.139446 sec/batch\n",
      "Epoch: 3/10\t Training step: 40\t Batch loss: 3.0044\t 4.721643 sec/batch\n",
      "Epoch: 3/10\t Training step: 41\t Batch loss: 3.2327\t 3.958107 sec/batch\n",
      "Epoch: 3/10\t Training step: 42\t Batch loss: 2.9788\t 4.012635 sec/batch\n",
      "Epoch: 3/10\t Training step: 43\t Batch loss: 2.9071\t 3.986605 sec/batch\n",
      "Epoch: 3/10\t Training step: 44\t Batch loss: 3.1144\t 3.522055 sec/batch\n",
      "Epoch: 3/10\t Training step: 45\t Batch loss: 3.2669\t 3.347877 sec/batch\n",
      "Epoch: 4/10\t Training step: 46\t Batch loss: 2.9589\t 3.405673 sec/batch\n",
      "Epoch: 4/10\t Training step: 47\t Batch loss: 3.1393\t 3.352331 sec/batch\n",
      "Epoch: 4/10\t Training step: 48\t Batch loss: 2.8677\t 3.887831 sec/batch\n",
      "Epoch: 4/10\t Training step: 49\t Batch loss: 3.0012\t 3.363733 sec/batch\n",
      "Epoch: 4/10\t Training step: 50\t Batch loss: 3.1702\t 3.397440 sec/batch\n",
      "Epoch: 4/10\t Training step: 51\t Batch loss: 3.2972\t 3.368816 sec/batch\n",
      "Epoch: 4/10\t Training step: 52\t Batch loss: 2.8892\t 3.267612 sec/batch\n",
      "Epoch: 4/10\t Training step: 53\t Batch loss: 2.9300\t 3.248302 sec/batch\n",
      "Epoch: 4/10\t Training step: 54\t Batch loss: 3.0932\t 3.353515 sec/batch\n",
      "Epoch: 4/10\t Training step: 55\t Batch loss: 2.8771\t 3.500380 sec/batch\n",
      "Epoch: 4/10\t Training step: 56\t Batch loss: 3.0805\t 3.858434 sec/batch\n",
      "Epoch: 4/10\t Training step: 57\t Batch loss: 2.8195\t 4.081432 sec/batch\n",
      "Epoch: 4/10\t Training step: 58\t Batch loss: 2.7435\t 3.564151 sec/batch\n",
      "Epoch: 4/10\t Training step: 59\t Batch loss: 2.9255\t 3.694972 sec/batch\n",
      "Epoch: 4/10\t Training step: 60\t Batch loss: 3.0607\t 3.326954 sec/batch\n",
      "Epoch: 5/10\t Training step: 61\t Batch loss: 2.7674\t 3.281418 sec/batch\n",
      "Epoch: 5/10\t Training step: 62\t Batch loss: 2.9581\t 3.401454 sec/batch\n",
      "Epoch: 5/10\t Training step: 63\t Batch loss: 2.6921\t 3.911183 sec/batch\n",
      "Epoch: 5/10\t Training step: 64\t Batch loss: 2.8203\t 3.639540 sec/batch\n",
      "Epoch: 5/10\t Training step: 65\t Batch loss: 3.0097\t 3.637850 sec/batch\n",
      "Epoch: 5/10\t Training step: 66\t Batch loss: 3.1401\t 3.529370 sec/batch\n",
      "Epoch: 5/10\t Training step: 67\t Batch loss: 2.7398\t 3.622860 sec/batch\n",
      "Epoch: 5/10\t Training step: 68\t Batch loss: 2.7802\t 3.845341 sec/batch\n",
      "Epoch: 5/10\t Training step: 69\t Batch loss: 2.9529\t 3.927811 sec/batch\n",
      "Epoch: 5/10\t Training step: 70\t Batch loss: 2.7341\t 3.917189 sec/batch\n",
      "Epoch: 5/10\t Training step: 71\t Batch loss: 2.9414\t 3.992440 sec/batch\n",
      "Epoch: 5/10\t Training step: 72\t Batch loss: 2.6901\t 3.946174 sec/batch\n",
      "Epoch: 5/10\t Training step: 73\t Batch loss: 2.6168\t 4.297322 sec/batch\n",
      "Epoch: 5/10\t Training step: 74\t Batch loss: 2.8052\t 4.371171 sec/batch\n",
      "Epoch: 5/10\t Training step: 75\t Batch loss: 2.9368\t 4.343395 sec/batch\n",
      "Epoch: 6/10\t Training step: 76\t Batch loss: 2.6464\t 6.574928 sec/batch\n",
      "Epoch: 6/10\t Training step: 77\t Batch loss: 2.8395\t 5.691105 sec/batch\n",
      "Epoch: 6/10\t Training step: 78\t Batch loss: 2.5784\t 4.784161 sec/batch\n",
      "Epoch: 6/10\t Training step: 79\t Batch loss: 2.7146\t 4.787090 sec/batch\n",
      "Epoch: 6/10\t Training step: 80\t Batch loss: 2.9024\t 4.558985 sec/batch\n",
      "Epoch: 6/10\t Training step: 81\t Batch loss: 3.0317\t 5.059868 sec/batch\n",
      "Epoch: 6/10\t Training step: 82\t Batch loss: 2.6343\t 4.111783 sec/batch\n",
      "Epoch: 6/10\t Training step: 83\t Batch loss: 2.6747\t 3.335864 sec/batch\n",
      "Epoch: 6/10\t Training step: 84\t Batch loss: 2.8458\t 3.316390 sec/batch\n",
      "Epoch: 6/10\t Training step: 85\t Batch loss: 2.6285\t 3.358493 sec/batch\n",
      "Epoch: 6/10\t Training step: 86\t Batch loss: 2.8413\t 3.496229 sec/batch\n",
      "Epoch: 6/10\t Training step: 87\t Batch loss: 2.5946\t 3.907758 sec/batch\n",
      "Epoch: 6/10\t Training step: 88\t Batch loss: 2.5287\t 3.357497 sec/batch\n",
      "Epoch: 6/10\t Training step: 89\t Batch loss: 2.7200\t 3.381539 sec/batch\n",
      "Epoch: 6/10\t Training step: 90\t Batch loss: 2.8574\t 3.437578 sec/batch\n",
      "Epoch: 7/10\t Training step: 91\t Batch loss: 2.5691\t 3.310139 sec/batch\n",
      "Epoch: 7/10\t Training step: 92\t Batch loss: 2.7626\t 3.350180 sec/batch\n",
      "Epoch: 7/10\t Training step: 93\t Batch loss: 2.5050\t 3.373011 sec/batch\n",
      "Epoch: 7/10\t Training step: 94\t Batch loss: 2.6402\t 3.406090 sec/batch\n",
      "Epoch: 7/10\t Training step: 95\t Batch loss: 2.8258\t 3.400676 sec/batch\n",
      "Epoch: 7/10\t Training step: 96\t Batch loss: 2.9563\t 3.437182 sec/batch\n",
      "Epoch: 7/10\t Training step: 97\t Batch loss: 2.5633\t 3.360814 sec/batch\n",
      "Epoch: 7/10\t Training step: 98\t Batch loss: 2.6061\t 3.314489 sec/batch\n",
      "Epoch: 7/10\t Training step: 99\t Batch loss: 2.7770\t 3.622811 sec/batch\n",
      "Epoch: 7/10\t Training step: 100\t Batch loss: 2.5658\t 3.919386 sec/batch\n",
      "Epoch: 7/10\t Training step: 101\t Batch loss: 2.7766\t 3.921887 sec/batch\n",
      "Epoch: 7/10\t Training step: 102\t Batch loss: 2.5341\t 4.207752 sec/batch\n",
      "Epoch: 7/10\t Training step: 103\t Batch loss: 2.4695\t 4.847578 sec/batch\n",
      "Epoch: 7/10\t Training step: 104\t Batch loss: 2.6620\t 4.753566 sec/batch\n",
      "Epoch: 7/10\t Training step: 105\t Batch loss: 2.8010\t 4.816043 sec/batch\n",
      "Epoch: 8/10\t Training step: 106\t Batch loss: 2.5093\t 5.492668 sec/batch\n",
      "Epoch: 8/10\t Training step: 107\t Batch loss: 2.7077\t 6.330588 sec/batch\n",
      "Epoch: 8/10\t Training step: 108\t Batch loss: 2.4508\t 5.812848 sec/batch\n",
      "Epoch: 8/10\t Training step: 109\t Batch loss: 2.5856\t 4.402180 sec/batch\n",
      "Epoch: 8/10\t Training step: 110\t Batch loss: 2.7725\t 4.281812 sec/batch\n",
      "Epoch: 8/10\t Training step: 111\t Batch loss: 2.9028\t 4.754935 sec/batch\n",
      "Epoch: 8/10\t Training step: 112\t Batch loss: 2.5119\t 4.466775 sec/batch\n",
      "Epoch: 8/10\t Training step: 113\t Batch loss: 2.5549\t 3.597524 sec/batch\n",
      "Epoch: 8/10\t Training step: 114\t Batch loss: 2.7268\t 3.931243 sec/batch\n",
      "Epoch: 8/10\t Training step: 115\t Batch loss: 2.5181\t 3.540423 sec/batch\n",
      "Epoch: 8/10\t Training step: 116\t Batch loss: 2.7276\t 3.326658 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/10\t Training step: 117\t Batch loss: 2.4866\t 3.343993 sec/batch\n",
      "Epoch: 8/10\t Training step: 118\t Batch loss: 2.4224\t 3.326502 sec/batch\n",
      "Epoch: 8/10\t Training step: 119\t Batch loss: 2.6137\t 3.354819 sec/batch\n",
      "Epoch: 8/10\t Training step: 120\t Batch loss: 2.7522\t 3.332219 sec/batch\n",
      "Epoch: 9/10\t Training step: 121\t Batch loss: 2.4583\t 3.358143 sec/batch\n",
      "Epoch: 9/10\t Training step: 122\t Batch loss: 2.6633\t 3.343000 sec/batch\n",
      "Epoch: 9/10\t Training step: 123\t Batch loss: 2.4086\t 3.380288 sec/batch\n",
      "Epoch: 9/10\t Training step: 124\t Batch loss: 2.5425\t 3.333640 sec/batch\n",
      "Epoch: 9/10\t Training step: 125\t Batch loss: 2.7286\t 3.387986 sec/batch\n",
      "Epoch: 9/10\t Training step: 126\t Batch loss: 2.8592\t 3.480861 sec/batch\n",
      "Epoch: 9/10\t Training step: 127\t Batch loss: 2.4689\t 3.383580 sec/batch\n",
      "Epoch: 9/10\t Training step: 128\t Batch loss: 2.5122\t 3.338818 sec/batch\n",
      "Epoch: 9/10\t Training step: 129\t Batch loss: 2.6873\t 3.475293 sec/batch\n",
      "Epoch: 9/10\t Training step: 130\t Batch loss: 2.4790\t 3.975580 sec/batch\n",
      "Epoch: 9/10\t Training step: 131\t Batch loss: 2.6867\t 4.029748 sec/batch\n",
      "Epoch: 9/10\t Training step: 132\t Batch loss: 2.4464\t 4.024761 sec/batch\n",
      "Epoch: 9/10\t Training step: 133\t Batch loss: 2.3849\t 3.924635 sec/batch\n",
      "Epoch: 9/10\t Training step: 134\t Batch loss: 2.5769\t 3.990134 sec/batch\n",
      "Epoch: 9/10\t Training step: 135\t Batch loss: 2.7167\t 3.967828 sec/batch\n",
      "Epoch: 10/10\t Training step: 136\t Batch loss: 2.4162\t 3.340063 sec/batch\n",
      "Epoch: 10/10\t Training step: 137\t Batch loss: 2.6259\t 3.376980 sec/batch\n",
      "Epoch: 10/10\t Training step: 138\t Batch loss: 2.3745\t 3.395444 sec/batch\n",
      "Epoch: 10/10\t Training step: 139\t Batch loss: 2.5080\t 3.369846 sec/batch\n",
      "Epoch: 10/10\t Training step: 140\t Batch loss: 2.6954\t 3.406289 sec/batch\n",
      "Epoch: 10/10\t Training step: 141\t Batch loss: 2.8271\t 3.374466 sec/batch\n",
      "Epoch: 10/10\t Training step: 142\t Batch loss: 2.4378\t 3.352898 sec/batch\n",
      "Epoch: 10/10\t Training step: 143\t Batch loss: 2.4806\t 3.333915 sec/batch\n",
      "Epoch: 10/10\t Training step: 144\t Batch loss: 2.6546\t 3.341077 sec/batch\n",
      "Epoch: 10/10\t Training step: 145\t Batch loss: 2.4490\t 5.124043 sec/batch\n",
      "Epoch: 10/10\t Training step: 146\t Batch loss: 2.6564\t 5.735072 sec/batch\n",
      "Epoch: 10/10\t Training step: 147\t Batch loss: 2.4156\t 4.187894 sec/batch\n",
      "Epoch: 10/10\t Training step: 148\t Batch loss: 2.3551\t 4.797067 sec/batch\n",
      "Epoch: 10/10\t Training step: 149\t Batch loss: 2.5443\t 4.542552 sec/batch\n",
      "Epoch: 10/10\t Training step: 150\t Batch loss: 2.6821\t 4.339517 sec/batch\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "save_every_n = 100\n",
    "#saver = tf.train.Saver(max_to_keep=100)\n",
    "\n",
    "model = LanguageModel()\n",
    "\n",
    "\n",
    "# Summary / Variables used for Tensorboard\n",
    "from datetime import datetime\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "logdir = \"train\"\n",
    "traindir = \"{}/time-{}/\".format(logdir, now)\n",
    "loss_summary = tf.summary.scalar('loss', model.loss)\n",
    "train_writer = tf.summary.FileWriter(traindir, tf.get_default_graph())\n",
    "\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    \n",
    "    counter = 0\n",
    "    for ep in range(epochs):\n",
    "        new_state = sess.run(model.initial_state)\n",
    "        loss = 0\n",
    "        for x, y in get_batches(source, batch_size):\n",
    "            counter += 1\n",
    "            start = time.time()\n",
    "            feed_dict = {model.inputs: x,\n",
    "                         model.targets: y,\n",
    "                         model.keep_prob: keep_prob,\n",
    "                         model.initial_state: new_state}\n",
    "            batch_loss, new_state, loss_summ, _ = sess.run([model.loss,\n",
    "                                                 model.final_state,\n",
    "                                                 loss_summary,\n",
    "                                                 model.optimizer],\n",
    "                                                 feed_dict=feed_dict)\n",
    "            stop = time.time()\n",
    "            step = counter * batch_size\n",
    "            train_writer.add_summary(loss_summ, step)\n",
    "            \n",
    "            print('Epoch: {}/{}\\t'.format(ep+1, epochs),\n",
    "                  'Training step: {}\\t'.format(counter),\n",
    "                  'Batch loss: {:.4f}\\t'.format(batch_loss),\n",
    "                  '{:4f} sec/batch'.format(stop-start))\n",
    "    train_writer.close()\n",
    "    #saver.save(sess, 'checkpoints/{}'.format(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-19T21:20:34.375054Z",
     "start_time": "2018-03-19T21:20:34.368620Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'embedding_matrix:0' shape=(20000, 100) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/basic_lstm_cell/kernel:0' shape=(612, 2048) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/basic_lstm_cell/bias:0' shape=(2048,) dtype=float32_ref>,\n",
       " <tf.Variable 'softmax/softmax_weight:0' shape=(512, 20000) dtype=float32_ref>,\n",
       " <tf.Variable 'softmax/softmax_bias:0' shape=(20000,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
