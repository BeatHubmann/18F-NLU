{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Description-Task-1:-RNN-Language-Modelling-(30-+10-Points)\" data-toc-modified-id=\"Description-Task-1:-RNN-Language-Modelling-(30-+10-Points)-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Description Task 1: RNN Language Modelling (30 +10 Points)</a></span><ul class=\"toc-item\"><li><span><a href=\"#1a)-Language-Modelling-(30-Points)\" data-toc-modified-id=\"1a)-Language-Modelling-(30-Points)-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>1a) Language Modelling (30 Points)</a></span></li><li><span><a href=\"#Conditional-Generation-(10-Points)\" data-toc-modified-id=\"Conditional-Generation-(10-Points)-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Conditional Generation (10 Points)</a></span></li></ul></li><li><span><a href=\"#Code-for-Task-1\" data-toc-modified-id=\"Code-for-Task-1-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Code for Task 1</a></span><ul class=\"toc-item\"><li><span><a href=\"#Task-1.1\" data-toc-modified-id=\"Task-1.1-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Task 1.1</a></span><ul class=\"toc-item\"><li><span><a href=\"#Setup-and-preparation\" data-toc-modified-id=\"Setup-and-preparation-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Setup and preparation</a></span></li><li><span><a href=\"#Data-preprocessing\" data-toc-modified-id=\"Data-preprocessing-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Data preprocessing</a></span></li><li><span><a href=\"#RNN\" data-toc-modified-id=\"RNN-2.1.3\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>RNN</a></span></li><li><span><a href=\"#Training\" data-toc-modified-id=\"Training-2.1.4\"><span class=\"toc-item-num\">2.1.4&nbsp;&nbsp;</span>Training</a></span></li><li><span><a href=\"#Sample-and-test\" data-toc-modified-id=\"Sample-and-test-2.1.5\"><span class=\"toc-item-num\">2.1.5&nbsp;&nbsp;</span>Sample and test</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Understanding: Project 1\n",
    "\n",
    "[__Natural Language Understanding, Spring 2018, ETHZ__](http://www.da.inf.ethz.ch/teaching/2018/NLU/)\n",
    "\n",
    "[__Project 1__ (ETHZ network)](http://www.da.inf.ethz.ch/teaching/2018/NLU/material/project.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project to-do list:\n",
    "\n",
    "Somewhat in order of importance:\n",
    "\n",
    "- ~~change code to unroll RNN in time instead of using dynamic_rnn~~\n",
    "- ~~make sure the target data fed into the crossentropy metric is really in correct form~~\n",
    "- ~~try own implementation of basic RNN cell instead of TF-prefab RNN or LSTM cell~~\n",
    "- ~~change implementation to use the Xavier initializer instead of the uniform distribution currently used (see below)~~\n",
    "- ~~change all `tf.Variable` variable inits to the better practice form like `W = tf.get_variable(name='example', shape=[784, 256], initializer=tf.contrib.layers.xavier_initializer())` which also includes the proper weight init~~\n",
    "- ~~include dropout at input and/or RNN cell level for regularization~~\n",
    "- ~~clean up namespaces, tensor naming~~\n",
    "- ~~(Started 2.4.2018, but TBC)** build in all reporting for Tensorboard~~\n",
    "- ~~adapt code to allow for differently sized timesteps~~\n",
    "- ~~make arrangements to save trained model~~\n",
    "- implement perplexity function\n",
    "- **(WIP): Maybe needs rewrite to use stock LSTM cell again** implement sampling function for conditional text generation\n",
    "- implement result output function\n",
    "- adapt code to allow for use of pretrained word2vec embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description Task 1: RNN Language Modelling (30 +10 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a) Language Modelling (30 Points)\n",
    "Your task is to build a simple LSTM language model. To be precise, we assume that words are independent given the recurrent hidden state; we compute a new hidden state given the last hidden state and last word, and predict the next word given the hidden state:\n",
    "$$ P(w_1,\\dots,w_n) = 􏰀\\prod_{t=1}^{n}P(w_t|\\mathbf{h}_t)$$\n",
    "$$ P(w_t|\\mathbf{h}_t) = \\text{softmax}(\\mathbf{Wh}_t)$$\n",
    "$$ \\mathbf{h}_t = f(\\mathbf{h}_{t−1}, w_{t-1}^{*})$$\n",
    "\n",
    "where $f$ is the LSTM recurrent function, $\\mathbf{W} \\in \\mathbb{R}^{|V|×d}$ are softmax weights and $\\mathbf{h_0}$ is either an all-zero constant or a trainable parameter.\n",
    "You can use the tensorflow cell implementation __[1](https://www.tensorflow.org/api_docs/python/tf/nn/rnn_cell)__ to carry out the recurrent computation in $f$. However, you must construct the actual RNN yourself (e.g. don’t use tensorflow’s `static_rnn` or `dynamic_rnn` or any other RNN library). That means, you will need to use a python loop that sets up the unrolled graph. To make your life simpler, please follow these design choices:\n",
    "\n",
    "__Model and Data specification__\n",
    "\n",
    "- Use a special sentence-beginning symbol `<bos>` and a sentence-end symbol `<eos>` (please use exactly these, including brackets). The `<bos>` symbol is the input, when predicting the first word and the `<eos>` symbol you require your model to predict at the end of every sentence.\n",
    "- Use a maximum sentence length of 30 (including the `<bos>` and `<eos>` symbol). Ignore longer sentences during training and testing.\n",
    "- Use a special padding symbol `<pad>` (please use exactly this, including brackets) to fill up sentences of length shorter than 30. This way, all your input will have the same size.\n",
    "- Use a vocabulary consisting of the 20K most frequent words in the training set, including the symbols `<bos>`, `<eos>`, `<pad>` and `<unk>`. Replace out-of-vocabulary words with the `<unk>` symbol before feeding them into your network (don’t change the file content).\n",
    "- Provide the ground truth last word as input to the RNN, not the last word you predicted. This is common practice.\n",
    "- Language models are usually trained to minimize the cross-entropy. Use tensorflow’s `tf.nn.sparse_softmax_cross_entropy_with_logits` to compute the loss (*This operation fuses the computation of the soft-max and the cross entropy loss given the logits. For numerical stability, it’s very important to use this function.*). Use the AdamOptimizer with default parameters to minimize the loss. Use `tf.clip_by_global_norm` to clip the norm of the gradients to 5.\n",
    "- Use a batch size of 64.\n",
    "- Use the data at __[6](https://polybox.ethz.ch/index.php/s/qUc2NvUh2eONfEB)__. Don’t pre-process the input further. All the data is already white-space tokenized and\n",
    "lower-cased. One sentence per line.\n",
    "- To initialize your weight matrices, use the `tf.contrib.layers.xavier_initializer()` initializer introduced in __[5](http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf)__.\n",
    "\n",
    "__Experiments__\n",
    "All experiments should not run for longer than, say, four hours on the GPU. For this task, your\n",
    "grade won’t improve with performance.\n",
    "\n",
    "- __Experiment A__: Train your model with word-embedding dimensionality of 100 and a hidden state size of 512 and compute sentence perplexity on the evaluation set (see submission format below).\n",
    "- __Experiment B__: It is common practice, to pretrain word embeddings using e.g. `word2vec`. This should make your model train faster as words will come already with some useful representation. Use the code at __[3](http://da.inf.ethz.ch/teaching/2018/NLU/material/load_embeddings.py)__ to load these word embeddings __[4](https://polybox.ethz.ch/index.php/s/cpicEJeC2G4tq9U)__ trained on the same corpus. Train your model again and compute evaluation perplexity.\n",
    "- __Experiment C__: It is often desirable to make the LSTM more powerful, by increasing the hidden dimensionality. However, this will naturally increase the parameters $\\mathbf{W}$ of the softmax. As a compromise, one can use a larger hidden state, but down-project it before the softmax. Increase the hidden state dimensionality from 512 to 1024, but down-project $h_t$ to dimensionality 512 before predicting $w_t$ as in\n",
    "$$ \\mathbf{\\tilde{h}}_t = \\mathbf{W}_P\\mathbf{h}_t$$\n",
    "where $W_P$ are parameters. Train your model again and compute evaluation perplexity.\n",
    "\n",
    "__Submission and grading__\n",
    "- Grading scheme: 100% correctness.\n",
    "- Deadline April 20th, 23:59:59.\n",
    "- You are not allowed to copy-paste any larger code blocks from existing implementations.\n",
    "- Hand in\n",
    "    - Your python code\n",
    "    - __Three__ result files containing sentence-level perplexity numbers on the __test__ set (to be distributed) for\n",
    "all three experiments. Recall that perplexity of a sentence $S = ⟨w_1, \\dots , w_n⟩$ with respect to your model $p(w_t|w_1, \\dots, w_{t−1})$ is defined as\n",
    "$$ \\text{Perp} = 2^{-\\frac{1}{n} \\sum_{t=1}^{n}\\log_2 p(w_t|w_1,\\dots,w_{t−1})}$$\n",
    "The `<eos>` symbol is part of the sequence, while the `<pad>` symbols (if any) are not. Be sure to have the basis of the exponential and the logarithm match.<br>\n",
    "__Input format sentences.test__<br>\n",
    "One sentence (none of them is longer than 28 tokens) per line:<br>\n",
    "         ```beside her , jamie bounced on his seat .\n",
    "         i looked and saw claire montgomery looking up at me .\n",
    "         people might not know who alex was , but they knew to listen to him .```<br>\n",
    "__Required output format groupXX.perplexityY__<br>\n",
    "(where XX is your group __number__ and Y ∈ {A,B,C} is the experiment). One perplexity number per line:<br>\n",
    "         $10.232$<br>\n",
    "         $2.434$<br>\n",
    "         $5.232$<br>\n",
    "Make sure to have equally many lines in the output as there are in the input – otherwise your submission will be rejected automatically.\n",
    "    - You have to submit at https://cmt3.research.microsoft.com/NLUETHZ2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Generation (10 Points)\n",
    "Let’s use your trained language model from above to generate sentences. Given an initial sequence of words, your are asked to __greedily__ generate words until either your model decides to finish the sentence (it generated `<eos>`) or a given maximum length has been reached. Note, that this task does not involve any training. Please see the tensorflow documentation on how to save and restore your model from above.\n",
    "There are several ways how to implement the generation. For example, you can define a graph that computes just one step of the RNN given the last input and the last state (both from a new placeholder).\n",
    "$$ \\text{state}_t, p_t = f(\\text{state}_{t−1},w_{t−1}) $$\n",
    "That means, for a prefix of size $m$ and a desired length of $n$, you run this graph $n$ times. The first $m + 1$ times you take the input form the prefix. For the rest of the sequence, you take the most likely2 word $w^{t−1} = \\text{argmax}_w p_{t−1}(w)$ from the last step.\n",
    "\n",
    "- Grading scheme: 100% correctness.\n",
    "- Deadline April 20th, 23:59:59.\n",
    "- You are not allowed to copy-paste any larger code blocks from existing implementations.\n",
    "- Hand in\n",
    "    - Your python code\n",
    "    - Your continued sentences of length up to 20. Use your trained model from experiment __C__ in task 1.1.\n",
    "    __Input format sentences.continuation__ One sentence (of length less than 20) per line:<br>\n",
    "         ```beside her ,\n",
    "         i\n",
    "         people might not know```<br>\n",
    "    The `<bos>` symbol is not explicitly in the file, but you should still use it as the first input.<br>\n",
    "    __Required output format groupXX.continuation__ (where XX is your __group number__)<br>\n",
    "         ```beside her , something happened ! <eos>\n",
    "         i do n’t recall making a noise , but i must have , because bob just looked up from his\n",
    "         people might not know the answer . <eos>```\n",
    "    - You have to submit at https://cmt3.research.microsoft.com/NLUETHZ2018\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-18T06:26:00.314606Z",
     "start_time": "2018-03-18T06:26:00.303743Z"
    }
   },
   "source": [
    "__Infrastructure__\n",
    "\n",
    "You must use Tensorflow, but any programming language is allowed. However, we strongly recommend `python3`. You have access to two compute resources: Unlimited CPU usage on Euler and GPU usage on Leonhard. Note that the difference in speed is typically a factor between 10 and 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for Task 1\n",
    "### Task 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-18T08:22:42.147335Z",
     "start_time": "2018-03-18T08:22:42.144046Z"
    }
   },
   "source": [
    "#### Setup and preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-18T07:22:12.364855Z",
     "start_time": "2018-03-18T07:22:12.360292Z"
    }
   },
   "source": [
    "Make sure you have done the following:\n",
    "\n",
    "- Download data from https://polybox.ethz.ch/index.php/s/qUc2NvUh2eONfEB and unpack into `./data/` subdirectory\n",
    "- Download embeddings from https://polybox.ethz.ch/index.php/s/cpicEJeC2G4tq9U and unpack into `./data/` subdirectory\n",
    "- Download helper function from http://da.inf.ethz.ch/teaching/2018/NLU/material/load_embeddings.py and put into `./helpers/` subdirectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T14:51:04.302615Z",
     "start_time": "2018-04-06T14:51:04.293081Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "from collections import Counter\n",
    "from helpers.load_embeddings import load_embedding\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T14:51:05.614565Z",
     "start_time": "2018-04-06T14:51:05.332892Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read all data from files\n",
    "\n",
    "with open('./data/sentences.train', 'r') as f:\n",
    "    train_data = f.read()\n",
    "    \n",
    "with open('./data/sentences.eval', 'r') as f:\n",
    "    eval_data = f.read()\n",
    "    \n",
    "with open('./data/sentences.continuation', 'r') as f:\n",
    "    continuation_data = f.read()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T14:51:06.561567Z",
     "start_time": "2018-04-06T14:51:06.553773Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data sample:\n",
      " ====================\n",
      "`` i 've never had any ice-cream for myself , my father never let me have any . ''\n",
      "`` and even if sh \n",
      " ................................................................................\n",
      "\n",
      " Evaluation data sample:\n",
      " ====================\n",
      "he took my face in his hands and held my face where he wanted it as he kissed me senseless .\n",
      "`` on t \n",
      " ................................................................................\n",
      "\n",
      " Continuation data sample:\n",
      " ====================\n",
      "`` no ,\n",
      "correct ...\n",
      "`` i\n",
      "peter\n",
      "what was i\n",
      "when he\n",
      "take some of\n",
      "id told\n",
      "throw\n",
      "we have no place\n",
      "i felt \n",
      " ................................................................................\n"
     ]
    }
   ],
   "source": [
    "# Have a peek at the given raw data\n",
    "\n",
    "print('Training data sample:\\n', 20*'=')\n",
    "print(train_data[:100], '\\n', 80*'.')\n",
    "\n",
    "print('\\n Evaluation data sample:\\n', 20*'=')\n",
    "print(eval_data[:100], '\\n', 80*'.')\n",
    "\n",
    "print('\\n Continuation data sample:\\n', 20*'=')\n",
    "print(continuation_data[:100], '\\n', 80*'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T14:51:25.491290Z",
     "start_time": "2018-04-06T14:51:07.290377Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample training sentences:\n",
      " [\"`` i 've never had any ice-cream for myself , my father never let me have any . ''\", \"`` and even if she was , the gargoyle could hardly halt me from harming her . ''\", 'pigafetta repeated the threat , which had no apparent effect .', \"best to barricade oneself , no ? ''\", \"`` why would he lie ? ''\"] \n",
      "\n",
      "Sample words:\n",
      " ['``', 'i', \"'ve\", 'never', 'had', 'any', 'ice-cream', 'for', 'myself', ',', 'my', 'father', 'never', 'let', 'me', 'have', 'any', '.', \"''\", '``'] \n",
      "\n",
      "Top frequency words:\n",
      " ['.', ',', 'the', 'i', 'to', 'and', '``', \"''\", 'a', 'he', 'of', 'you', 'was', 'her', 'it', 'she', 'in', 'his', 'that', '?'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Splitting data into sentences\n",
    "def split_data2sentences(data):\n",
    "    text = ''.join(data)\n",
    "    sentences = text.split('\\n')\n",
    "    return sentences\n",
    "\n",
    "train_sentences = split_data2sentences(train_data)\n",
    "eval_sentences = split_data2sentences(eval_data)\n",
    "continuation_sentences = split_data2sentences(continuation_data)\n",
    "\n",
    "## We generate the dictionary from the training data, so this treatment is different\n",
    "\n",
    "# Get sentences from training data and look at sample\n",
    "print('Sample training sentences:\\n', train_sentences[:5], '\\n')\n",
    "\n",
    "# Make text contiguous again, break into words for vocabulary and look at sample\n",
    "words = ' '.join(train_sentences).split()\n",
    "print('Sample words:\\n', words[:20], '\\n')\n",
    "\n",
    "# Make a word counter and show top frequency words\n",
    "counts = Counter(words)\n",
    "vocab = sorted(counts, key=counts.get, reverse=True)\n",
    "print('Top frequency words:\\n', vocab[:20], '\\n')\n",
    "\n",
    "# Clip word counter to defined length [20k] and append special symbol words\n",
    "symbols = ['<bos>', '<eos>', '<pad>', '<unk>']\n",
    "vocab_length = 20000 # restrict to 20k most frequent tokens\n",
    "vocab = vocab[:vocab_length-len(symbols)] # kick out the last 4 to replace w/ symbols\n",
    "for each in symbols:\n",
    "    vocab.append(each)\n",
    "    \n",
    "# Make a vocabulary to convert words to integers\n",
    "vocab_to_int = {word: i for i, word in enumerate(vocab, 0)} # consider starting with 1 if 0 gives dead cells\n",
    "\n",
    "# Make a vocabulary to get words from integers at the end\n",
    "int_to_vocab = dict(enumerate(vocab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T14:51:36.386606Z",
     "start_time": "2018-04-06T14:51:35.777258Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 67737.47it/s]\n",
      "100%|██████████| 10001/10001 [00:00<00:00, 54255.96it/s]\n",
      "100%|██████████| 10001/10001 [00:00<00:00, 82983.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# Encode sentences to integers and insert symbol words where necessary\n",
    "\n",
    "### ATTN: Remove next line after finishing, keeping data set small for speedup\n",
    "train_sentences = train_sentences[:2000]\n",
    "\n",
    "def encode_sentences(sentences):\n",
    "    max_sentence_length = 30 # Given by task description\n",
    "    sentences_ints = [] # List to hold converted-to-int sentences\n",
    "    for each in tqdm(sentences):\n",
    "        sentence = each.split()\n",
    "        if len(sentence) < max_sentence_length-2: # -2 to allow for <bos>, <eos> \\\n",
    "                                                  # only use sentences w/ lenght <=30 as mandated\n",
    "            sentence_int = [vocab_to_int['<bos>']] # Start sentence list w/ <bos>\n",
    "            sentence_int += [vocab_to_int[word] if word in vocab_to_int\\\n",
    "                                 else vocab_to_int['<unk>'] for word in sentence] # Append remaining words\n",
    "            sentence_int.append(vocab_to_int['<eos>']) # End sentence w/ <eos>\n",
    "            while len(sentence_int) < max_sentence_length: # Pad length if necessary\n",
    "                sentence_int.append(vocab_to_int['<pad>'])\n",
    "            sentences_ints.append(sentence_int) \n",
    "    encoded = np.array(sentences_ints) # Convert list of sentences to np array\n",
    "    return encoded\n",
    "\n",
    "train_encoded = encode_sentences(train_sentences)\n",
    "eval_encoded = encode_sentences(eval_sentences)\n",
    "continuation_encoded = encode_sentences(continuation_sentences)\n",
    "\n",
    "# Set data preparation complete flag\n",
    "data_ready = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T14:51:42.840050Z",
     "start_time": "2018-04-06T14:51:42.829406Z"
    }
   },
   "outputs": [],
   "source": [
    "def variable_summaries(var):\n",
    "    '''Attach a lot of summaries to a Tensor (for TensorBoard visualization).\n",
    "    \n",
    "        From TensorBoard documentation\n",
    "    '''\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean', mean)\n",
    "    with tf.name_scope('stddev'):\n",
    "        stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "    tf.summary.scalar('stddev', stddev)\n",
    "    tf.summary.scalar('max', tf.reduce_max(var))\n",
    "    tf.summary.scalar('min', tf.reduce_min(var))\n",
    "    tf.summary.histogram('histogram', var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T14:51:49.062656Z",
     "start_time": "2018-04-06T14:51:49.057581Z"
    }
   },
   "outputs": [],
   "source": [
    "def init_rnn_cells(x, rnn_size):\n",
    "    '''Init RNN cells, setup reusable variables\n",
    "    \n",
    "        TBC\n",
    "    '''\n",
    "    # For readability: Short dimension handlers\n",
    "    N = x.shape[0] # Batch size\n",
    "    D = x.shape[1] # Input dimensions\n",
    "    H = rnn_size\n",
    "    \n",
    "    with tf.variable_scope('LSTM'):\n",
    "        W_x = tf.get_variable(name='W_x', shape=[D, 4*H], initializer=xavi) # Input-to-hidden\n",
    "        W_h = tf.get_variable(name='W_h', shape=[H, 4*H], initializer=xavi) #Hidden-to-hidden\n",
    "        b = tf.get_variable(name='b', shape=[4*H,], initializer=zeros)\n",
    "        h_init = tf.get_variable(name='h_init', shape=[N, H], initializer=zeros, trainable=False)\n",
    "        C_init = tf.get_variable(name='C_init', shape=[N, H], initializer=ones, trainable=False)\n",
    "    return h_init, C_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T14:51:59.144913Z",
     "start_time": "2018-04-06T14:51:59.134449Z"
    }
   },
   "outputs": [],
   "source": [
    "def rnn_cell(x, h_prev, C_prev):\n",
    "    '''Hand-made Basic LSTM cell\n",
    "    \n",
    "        For variable names see http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "    \n",
    "        Inputs:\n",
    "        x: Input data\n",
    "        prev_h: Previous hidden state, shape (batch_size, rnn_size)\n",
    "        prev_C: Previous cell state, shape (batch_size, rnn_size)\n",
    "        \n",
    "        Outputs:\n",
    "        h: Current hidden state, shape (batch_size, rnn_size)\n",
    "        C: Current cell state, shape (batch_size, rnn_size)\n",
    "        TBC\n",
    "    '''\n",
    "    \n",
    "    with tf.variable_scope('LSTM', reuse=True):\n",
    "        W_x = tf.get_variable('W_x') \n",
    "        W_h = tf.get_variable('W_h') \n",
    "        b = tf.get_variable('b')     \n",
    "        \n",
    "        variable_summaries(W_x)\n",
    "        variable_summaries(W_h)\n",
    "        variable_summaries(b)\n",
    "             \n",
    "    H = tf.cast(W_h.shape[0], tf.int32)\n",
    "    \n",
    "    A = tf.add(tf.add(tf.matmul(x, W_x), tf.matmul(h_prev, W_h)), b)\n",
    "    \n",
    "    f_t = tf.sigmoid(A[:, :H])\n",
    "    i_t = tf.sigmoid(A[:, H:2*H])\n",
    "    C_twiddle_t = tf.tanh(A[:, 2*H:3*H])\n",
    "    o_t = tf.sigmoid(A[:, 3*H:])\n",
    "    \n",
    "    C_t = f_t * C_prev + i_t * C_twiddle_t\n",
    " \n",
    "    h_t = o_t * tf.tanh(C_t)\n",
    "\n",
    "    return h_t, C_t\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T15:12:40.899248Z",
     "start_time": "2018-04-06T15:12:40.876841Z"
    }
   },
   "outputs": [],
   "source": [
    "class RNNLanguageModel:\n",
    "    '''Main element: Class representing the complete RNN language model\n",
    "    \n",
    "        TBC\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,\n",
    "                 out_size,\n",
    "                 batch_size,\n",
    "                 n_steps,\n",
    "                 rnn_size,\n",
    "                 rnn_size_factor,\n",
    "                 rnn_layers,\n",
    "                 learning_rate,\n",
    "                 grad_clip,\n",
    "                 embedding_size,\n",
    "                 sampling=False):\n",
    "        \n",
    "        # Adapt batch_size, n_steps for sampling\n",
    "        if (sampling == True):\n",
    "            batch_size, n_steps = 1, 1\n",
    "        else:\n",
    "            batch_size, n_steps = batch_size, n_steps\n",
    "        \n",
    "        # Reset tensorflow graph for clean slate\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        # Build input layer, keep_prob (all placeholders):\n",
    "        with tf.name_scope('input_layer'):\n",
    "            self.inputs = tf.placeholder(tf.int32, [batch_size, n_steps], name='inputs')\n",
    "            self.targets = tf.placeholder(tf.int64, [batch_size, n_steps], name='targets')\n",
    "            self.keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "            \n",
    "\n",
    "        # Build embedding layer\n",
    "        with tf.name_scope('embedding_layer'):\n",
    "            embedding_matrix = tf.get_variable(name='embedding_matrix',\n",
    "                                               shape=[vocab_length, embedding_size],\n",
    "                                               initializer=unif)\n",
    "            self.embeddings = tf.nn.embedding_lookup(embedding_matrix, self.inputs,\n",
    "                                                     name='inputs_embedding_lookup')\n",
    "            tf.summary.histogram('embeddings', self.embeddings) # for TensorBoard analysis\n",
    "            tf.summary.scalar('embeddings_dropout', keep_prob)\n",
    "            # Embedding layer dropout during training\n",
    "            if (keep_prob < 1):\n",
    "                self.embeddings = tf.nn.dropout(self.embeddings, keep_prob)\n",
    "            \n",
    "        # Build RNN layer\n",
    "        with tf.name_scope('hidden_layer'):\n",
    "            # LSTM cell init\n",
    "            self.h_init, self.C_init = init_rnn_cells(self.embeddings[:, 0, :], rnn_size*rnn_size_factor)\n",
    "            self.hidden_states, self.cell_states = [self.h_init], [self.C_init]\n",
    "            \n",
    "            # LSTM time steps\n",
    "            for i in range(n_steps):\n",
    "                h_prev, C_prev = self.hidden_states[-1], self.cell_states[-1]\n",
    "                h_t, C_t = rnn_cell(self.embeddings[:, i, :], h_prev, C_prev)\n",
    "                self.hidden_states.append(h_t), self.cell_states.append(C_t)\n",
    "        \n",
    "            self.final_hidden_state, self.final_cell_state = self.hidden_states[-1], self.cell_states[-1]\n",
    "            \n",
    "            # Reshape hidden_states into tensor w/ one row for e/a step, leave out initial state\n",
    "            self.outputs = tf.concat(self.hidden_states[1:], 0)\n",
    "            \n",
    "            tf.summary.scalar('hidden_dropout', keep_prob)\n",
    "            \n",
    "            # Hidden layer dropout during training\n",
    "            if (keep_prob < 1):\n",
    "                self.outputs = tf.nn.dropout(self.outputs, keep_prob)\n",
    "            \n",
    "            # If hidden layer increased by factor [1.1C] project down\n",
    "            if (rnn_size_factor > 1):\n",
    "                W_p = tf.get_variable(name='downprojection_weight', shape=[rnn_size*rnn_size_factor,\n",
    "                                                                          rnn_size],\n",
    "                                      initializer=xavi)\n",
    "                b_p = tf.get_variable(name='downprojection_bias', shape=[rnn_size,],\n",
    "                                      initializer=zeros)\n",
    "                \n",
    "                variable_summaries(W_p)\n",
    "                variable_summaries(b_p)\n",
    "                \n",
    "                self.outputs = tf.nn.xw_plus_b(self.outputs, W_p, b_p)\n",
    "                \n",
    "        # Build softmax output layer and calculate best prediction\n",
    "        with tf.name_scope('softmax_layer'):\n",
    "            # Hook up RNN outputs to softmax layer:\n",
    "            W_softmax = tf.get_variable(name=\"softmax_weight\", shape=[rnn_size, out_size],\n",
    "                                        initializer=xavi)\n",
    "            b_softmax = tf.get_variable(name=\"softmax_bias\", shape=[out_size],\n",
    "                                        initializer=zeros)\n",
    "            \n",
    "            variable_summaries(W_softmax)\n",
    "            variable_summaries(b_softmax)\n",
    "            \n",
    "            # Calculate logits from softmax layer\n",
    "            self.logits = tf.nn.xw_plus_b(self.outputs, W_softmax, b_softmax, name='logits')\n",
    "            \n",
    "            tf.summary.histogram('logits', self.logits)\n",
    "            \n",
    "            # Finally, get word probabilities from logits\n",
    "            self.predictions = tf.nn.softmax(self.logits, name='predictions')\n",
    "            \n",
    "            tf.summary.histogram('predictions', self.predictions)\n",
    "        \n",
    "        # Loss and accuracy\n",
    "        with tf.name_scope('loss_accuracy'):\n",
    "            # One-hot encode targets:\n",
    "            # To be confirmed, but after some consideration I now think its fine\n",
    "            y_one_hot = tf.one_hot(self.targets, out_size)\n",
    "\n",
    "            # Reshape encoded targets to fit logits\n",
    "            y_reshaped = tf.reshape(y_one_hot, self.logits.get_shape())\n",
    "\n",
    "            # Softmax cross entropy loss\n",
    "            self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=self.logits,\n",
    "                                                                               labels=y_reshaped))\n",
    "            \n",
    "            tf.summary.scalar('loss', self.loss)\n",
    "            \n",
    "            # Best prediction\n",
    "            self.best_prediction = tf.argmax(self.predictions, 1, name='best_prediction')\n",
    "            \n",
    "            # Accuracy\n",
    "            self.correct_predictions = None\n",
    "            self.accuracy = None\n",
    "            \n",
    "            # tf.summary.scalar('accuracy', self.accuracy)\n",
    "            \n",
    "        # Optimizer\n",
    "        with tf.name_scope('optimizer'):\n",
    "            tvars = tf.trainable_variables()\n",
    "            grads, _ = tf.clip_by_global_norm(tf.gradients(self.loss, tvars), grad_clip)\n",
    "            train_op = tf.train.AdamOptimizer(learning_rate)\n",
    "            self.optimizer = train_op.apply_gradients(zip(grads, tvars))      \n",
    "\n",
    "        # Merge summaries for TensorBoard    \n",
    "        self.merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T14:52:12.356872Z",
     "start_time": "2018-04-06T14:52:12.343071Z"
    }
   },
   "outputs": [],
   "source": [
    "class RNNConfig(object):\n",
    "    '''Class holding all configuration vars for training the RNN\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self,\n",
    "                 train_data__path='./data/sentences.train',\n",
    "                 eval_data__path='./data/sentences.eval',\n",
    "                 validation_split=.1,\n",
    "                 vocab_length=20000,\n",
    "                 embedding_size=100,\n",
    "                 rnn_size=512,\n",
    "                 rnn_size_factor=1,\n",
    "                 rnn_layers=1,\n",
    "                 n_steps=30,\n",
    "                 learning_rate=0.001,\n",
    "                 keep_prob=0.5,\n",
    "                 grad_clip=5.0,\n",
    "                 batch_size=64,\n",
    "                 num_epochs=10,\n",
    "                 evaluate_every=100,\n",
    "                 save_every_n=100,\n",
    "                 validate_every_n=100,\n",
    "                 max_to_keep=5,\n",
    "                 past_words=5):\n",
    "        \n",
    "        # Path to the training data \n",
    "        self.train_data__path = train_data__path\n",
    "        \n",
    "        # Path to the evaluation data \n",
    "        self.eval_data__path = eval_data__path\n",
    "        \n",
    "        # Percentage of the training data used for validation (default: 10%)\n",
    "        self.validation_split = validation_split\n",
    "        \n",
    "        # Size of the vocabulary (default: 20k)\n",
    "        self.vocab_length = vocab_length\n",
    "        \n",
    "        # Dimensionality of word embedding layer (default: 100)\n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        # Dimensionality of RNN (i.e. hidden) layer (default: 512)\n",
    "        self.rnn_size = rnn_size\n",
    "        \n",
    "        # Integer to factor the size of the hidden layer [Task 1.1C] (default: 1)\n",
    "        self.rnn_size_factor = rnn_size_factor\n",
    "        \n",
    "        # Number of RNN layers (default: 1)\n",
    "        self.rnn_layers = rnn_layers\n",
    "        \n",
    "        # Number of time steps for RNN (default: 30)\n",
    "        self.n_steps = n_steps\n",
    "        \n",
    "        # Size of softmax output (default: vocab_length)\n",
    "        self.out_size = self.vocab_length\n",
    "        \n",
    "        # Learning rate (default: 0.001)\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # Dropout rate (default: 0.5)\n",
    "        self.keep_prob = keep_prob\n",
    "        \n",
    "        # Gradient clipping treshold (default: 5.0)\n",
    "        self.grad_clip = grad_clip\n",
    "        \n",
    "        # Batch Size (default: 64)\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Number of training epochs (default: 10)\n",
    "        self.num_epochs = num_epochs\n",
    "        \n",
    "        # Evaluate model on dev set after this many steps (default: 100)\n",
    "        self.evaluate_every = evaluate_every\n",
    "        \n",
    "        # Save model after this many steps (default: 100)\n",
    "        self.save_every_n = save_every_n\n",
    "        \n",
    "        # Validate after this many steps (default: 100)\n",
    "        self.validate_every_n = validate_every_n\n",
    "        \n",
    "        # Number of checkpoints to save (default: 5)\n",
    "        self.max_to_keep = max_to_keep\n",
    "        \n",
    "        # How many previous words are used for prediction (default: 5)\n",
    "        self.past_words = past_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T14:52:21.308542Z",
     "start_time": "2018-04-06T14:52:21.300249Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build batch generator for training    \n",
    "def get_batches(source_arr, batch_size, n_steps):\n",
    "    '''Generator which returns features x and targets y of size:\n",
    "            batch_size(number of sequences from source_arr)\n",
    "                    x\n",
    "            n_steps (length of sequence from source_arr)\n",
    "    \n",
    "    Inputs\n",
    "    ------\n",
    "    source_arr: A np.ndarray of sentences in rows to generate features and targets from\n",
    "    batch_size: An int number of sequences required per batch\n",
    "    n_steps: Number of time steps for RNN to consider; defines sequence length\n",
    "    \n",
    "    Outputs\n",
    "    -------\n",
    "    x: A np.ndarray of feature sequences according to parameters above\n",
    "    y: A np.ndarray of target sequences according to paramteres above.\n",
    "    '''\n",
    "    # Make sure time steps doesn't exceed available information in sentence\n",
    "    assert (n_steps <=  source_arr.shape[1]), \"No point in further back than sentence is long\"\n",
    "    \n",
    "    # How many full, non-overlapping sequences we can get from a sentence\n",
    "    n_seq_per_row = source_arr.shape[1] // n_steps \n",
    "    \n",
    "    # Crop source to make full sequences only\n",
    "    source_length = n_steps * n_seq_per_row # Reflecting number of full sequences of wanted length per source sentence\n",
    "    source_arr = source_arr[:, :source_length] # Crop columns\n",
    "    \n",
    "    # Reshape to make our life easier\n",
    "    source_arr = source_arr.reshape((-1, n_steps)) # Now one row/sequence\n",
    "    \n",
    "    # Further crop source to make full batches only\n",
    "    n_batches = source_arr.shape[0] // batch_size # How many batches of wanted size w/ wanted sequence length we can get\n",
    "    source_arr = source_arr[:n_batches*batch_size, :] # Crop rows\n",
    "\n",
    "    # While in convenient shape: Shuffle rows of sequences to improve training\n",
    "    np.random.shuffle(source_arr)\n",
    "    \n",
    "    # Reshape again for later convenience\n",
    "    source_arr = source_arr.reshape((batch_size, -1))\n",
    "                        \n",
    "    # Finally generate batches: source_arr has now batch_size rows and we slide over the columns in steps of size n_steps\n",
    "    for j in range(0, source_arr.shape[1], n_steps):\n",
    "        # Feature sequence:\n",
    "        x = source_arr[:, j:j+n_steps]\n",
    "        # Target sequence: Shift feature sequence by one step, wrap around:\n",
    "        y = np.zeros_like(x) # Create empty\n",
    "        y[:, :-1]= x[:, 1:] # Center part with shift\n",
    "        y[:, -1] = x[:, 0] # Wrap around\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T15:19:07.964452Z",
     "start_time": "2018-04-06T15:12:55.345033Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2\t Training step: 1\t Batch loss: 9.9004\t 7.551590 sec/batch\n",
      "Epoch: 1/2\t Training step: 2\t Batch loss: 9.8044\t 5.106267 sec/batch\n",
      "Epoch: 1/2\t Training step: 3\t Batch loss: 9.6952\t 6.104924 sec/batch\n",
      "Epoch: 1/2\t Training step: 4\t Batch loss: 9.4261\t 4.869611 sec/batch\n",
      "Epoch: 1/2\t Training step: 5\t Batch loss: 8.9096\t 4.951221 sec/batch\n",
      "Epoch: 1/2\t Training step: 6\t Batch loss: 7.7544\t 6.406933 sec/batch\n",
      "Epoch: 1/2\t Training step: 7\t Batch loss: 6.8042\t 6.670255 sec/batch\n",
      "Epoch: 1/2\t Training step: 8\t Batch loss: 5.9426\t 5.781776 sec/batch\n",
      "Epoch: 1/2\t Training step: 9\t Batch loss: 5.0932\t 6.068569 sec/batch\n",
      "Epoch: 1/2\t Training step: 10\t Batch loss: 4.1858\t 4.990966 sec/batch\n",
      "Epoch: 1/2\t Training step: 11\t Batch loss: 3.7656\t 7.485211 sec/batch\n",
      "Epoch: 1/2\t Training step: 12\t Batch loss: 3.5786\t 7.690469 sec/batch\n",
      "Epoch: 1/2\t Training step: 13\t Batch loss: 3.3705\t 7.442109 sec/batch\n",
      "Epoch: 1/2\t Training step: 14\t Batch loss: 3.5717\t 5.943153 sec/batch\n",
      "Epoch: 1/2\t Training step: 15\t Batch loss: 3.4699\t 7.872775 sec/batch\n",
      "Epoch: 1/2\t Training step: 16\t Batch loss: 3.3912\t 5.367695 sec/batch\n",
      "Epoch: 1/2\t Training step: 17\t Batch loss: 3.9911\t 8.390803 sec/batch\n",
      "Epoch: 1/2\t Training step: 18\t Batch loss: 3.7879\t 6.824528 sec/batch\n",
      "Epoch: 1/2\t Training step: 19\t Batch loss: 3.5622\t 4.487433 sec/batch\n",
      "Epoch: 1/2\t Training step: 20\t Batch loss: 3.5952\t 7.110598 sec/batch\n",
      "Epoch: 1/2\t Training step: 21\t Batch loss: 3.8977\t 5.227538 sec/batch\n",
      "Epoch: 1/2\t Training step: 22\t Batch loss: 3.6834\t 5.904061 sec/batch\n",
      "Epoch: 1/2\t Training step: 23\t Batch loss: 3.7962\t 7.915283 sec/batch\n",
      "Epoch: 1/2\t Training step: 24\t Batch loss: 3.7400\t 4.351197 sec/batch\n",
      "Epoch: 1/2\t Training step: 25\t Batch loss: 3.8051\t 7.469207 sec/batch\n",
      "Epoch: 1/2\t Training step: 26\t Batch loss: 3.4723\t 7.775236 sec/batch\n",
      "Epoch: 1/2\t Training step: 27\t Batch loss: 3.3400\t 4.283953 sec/batch\n",
      "Epoch: 2/2\t Training step: 28\t Batch loss: 3.8691\t 6.926386 sec/batch\n",
      "Epoch: 2/2\t Training step: 29\t Batch loss: 3.4704\t 8.334288 sec/batch\n",
      "Epoch: 2/2\t Training step: 30\t Batch loss: 3.3494\t 8.611042 sec/batch\n",
      "Epoch: 2/2\t Training step: 31\t Batch loss: 3.3212\t 8.737335 sec/batch\n",
      "Epoch: 2/2\t Training step: 32\t Batch loss: 3.5633\t 6.305952 sec/batch\n",
      "Epoch: 2/2\t Training step: 33\t Batch loss: 3.4071\t 4.965543 sec/batch\n",
      "Epoch: 2/2\t Training step: 34\t Batch loss: 3.4290\t 7.369903 sec/batch\n",
      "Epoch: 2/2\t Training step: 35\t Batch loss: 3.7100\t 5.814936 sec/batch\n",
      "Epoch: 2/2\t Training step: 36\t Batch loss: 3.2826\t 6.348374 sec/batch\n",
      "Epoch: 2/2\t Training step: 37\t Batch loss: 3.2370\t 6.946903 sec/batch\n",
      "Epoch: 2/2\t Training step: 38\t Batch loss: 3.0307\t 5.319935 sec/batch\n",
      "Epoch: 2/2\t Training step: 39\t Batch loss: 3.4625\t 7.728898 sec/batch\n",
      "Epoch: 2/2\t Training step: 40\t Batch loss: 3.3965\t 4.977596 sec/batch\n",
      "Epoch: 2/2\t Training step: 41\t Batch loss: 3.3121\t 8.851243 sec/batch\n",
      "Epoch: 2/2\t Training step: 42\t Batch loss: 3.2641\t 8.502130 sec/batch\n",
      "Epoch: 2/2\t Training step: 43\t Batch loss: 3.1125\t 9.137468 sec/batch\n",
      "Epoch: 2/2\t Training step: 44\t Batch loss: 3.4309\t 8.826165 sec/batch\n",
      "Epoch: 2/2\t Training step: 45\t Batch loss: 3.2554\t 7.070554 sec/batch\n",
      "Epoch: 2/2\t Training step: 46\t Batch loss: 3.6498\t 5.224112 sec/batch\n",
      "Epoch: 2/2\t Training step: 47\t Batch loss: 3.5252\t 8.857627 sec/batch\n",
      "Epoch: 2/2\t Training step: 48\t Batch loss: 3.7093\t 8.867295 sec/batch\n",
      "Epoch: 2/2\t Training step: 49\t Batch loss: 3.4038\t 5.022207 sec/batch\n",
      "Epoch: 2/2\t Training step: 50\t Batch loss: 3.1779\t 6.312406 sec/batch\n",
      "Epoch: 2/2\t Training step: 51\t Batch loss: 3.4770\t 8.112400 sec/batch\n",
      "Epoch: 2/2\t Training step: 52\t Batch loss: 3.3016\t 7.937769 sec/batch\n",
      "Epoch: 2/2\t Training step: 53\t Batch loss: 3.5991\t 5.432183 sec/batch\n",
      "Epoch: 2/2\t Training step: 54\t Batch loss: 3.2709\t 7.592027 sec/batch\n"
     ]
    }
   ],
   "source": [
    "# Define shorthands for common initializers\n",
    "ones = tf.ones_initializer\n",
    "unif = tf.random_uniform_initializer(-1, 1)\n",
    "xavi = tf.contrib.layers.xavier_initializer()\n",
    "zeros = tf.zeros_initializer()\n",
    "\n",
    "# Set configuration for training\n",
    "CONFIG = RNNConfig(num_epochs=2 ,rnn_size_factor=1)\n",
    "\n",
    "# Check data preparation complete\n",
    "assert data_ready == True, 'Need to run data preparation first'\n",
    "\n",
    "# Split training/validation data\n",
    "np.random.seed(42)\n",
    "shuffled_rows_ind = np.random.permutation(len(train_encoded))\n",
    "validation_split_ind = int(CONFIG.validation_split * len(train_encoded))\n",
    "source_train = train_encoded[shuffled_rows_ind[validation_split_ind:]]\n",
    "source_validation = train_encoded[shuffled_rows_ind[:validation_split_ind]]\n",
    "\n",
    "# Set training loop variables\n",
    "num_epochs = CONFIG.num_epochs\n",
    "save_every_n = CONFIG.save_every_n\n",
    "validate_every_n = CONFIG.validate_every_n\n",
    "keep_prob = CONFIG.keep_prob\n",
    "\n",
    "# Create model instance\n",
    "model = RNNLanguageModel(out_size=CONFIG.out_size,\n",
    "                         batch_size=CONFIG.batch_size,\n",
    "                         n_steps=CONFIG.n_steps,\n",
    "                         rnn_size=CONFIG.rnn_size,\n",
    "                         rnn_size_factor=CONFIG.rnn_size_factor,\n",
    "                         rnn_layers=CONFIG.rnn_layers,\n",
    "                         learning_rate=CONFIG.learning_rate,\n",
    "                         grad_clip=CONFIG.grad_clip,\n",
    "                         embedding_size=CONFIG.embedding_size)\n",
    "\n",
    "# Setup TensorBoard logging\n",
    "now = time.strftime('%y-%m-%d-%H-%M-%S')\n",
    "log_dir = './runs'\n",
    "log_subdir = '{}/run-{}/'.format(log_dir, now)\n",
    "train_writer = tf.summary.FileWriter(log_subdir, tf.get_default_graph())\n",
    "\n",
    "# Setup model saving\n",
    "save_dir = './checkpoints'\n",
    "saver = tf.train.Saver(max_to_keep=CONFIG.max_to_keep)\n",
    "\n",
    "# Run training\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    counter = 0\n",
    "    for ep in range(num_epochs):\n",
    "        new_hidden_state, new_cell_state = sess.run([model.h_init, model.C_init])\n",
    "        loss = 0\n",
    "        \n",
    "        validation_batches = get_batches(source_validation, batch_size=CONFIG.batch_size,\n",
    "                                n_steps=CONFIG.n_steps)\n",
    "        \n",
    "        for x_train, y_train in get_batches(source_train, batch_size=CONFIG.batch_size,\n",
    "                                n_steps=CONFIG.n_steps):\n",
    "            counter += 1\n",
    "            start = time.time()\n",
    "            \n",
    "            feed_dict = {model.inputs: x_train,\n",
    "                         model.targets: y_train,\n",
    "                         model.keep_prob: keep_prob,\n",
    "                         model.h_init: new_hidden_state,\n",
    "                         model.C_init: new_cell_state}\n",
    "            \n",
    "            summary, batch_loss, new_hidden_state, new_cell_state, _ = \\\n",
    "            sess.run([model.merged, model.loss, model.final_hidden_state,\n",
    "                      model.final_cell_state, model.optimizer], feed_dict=feed_dict)\n",
    "            \n",
    "            batch_time = time.time() - start\n",
    "            \n",
    "            train_writer.add_summary(summary, counter)\n",
    "            \n",
    "            print('Epoch: {}/{}\\t'.format(ep+1, num_epochs),\n",
    "                  'Training step: {}\\t'.format(counter),\n",
    "                  'Batch loss: {:.4f}\\t'.format(batch_loss),\n",
    "                # 'Batch accuracy: {:.1%}\\t'.format(batch_accuracy),\n",
    "                  '{:4f} sec/batch'.format(batch_time))\n",
    "            \n",
    "            if (counter % save_every_n == 0):\n",
    "                saver.save(sess, '{}/run-{}_i{}_s{}.ckpt'.format(save_dir, now,\n",
    "                                                                 counter, CONFIG.rnn_size))\n",
    "            if (counter % validate_every_n == 0):\n",
    "                x_validation, y_validation = next(validation_batches)\n",
    "                feed_dict = {model.inputs: x_validation,\n",
    "                             model.targets: y_validation,\n",
    "                             model.keep_prob: 1.0,\n",
    "                             model.h_init: new_hidden_state,\n",
    "                             model.C_init: new_cell_state}\n",
    "                \n",
    "                validation_loss = sess.run(model.loss, feed_dict=feed_dict)\n",
    "                print('Epoch: {}/{}\\t'.format(ep+1, num_epochs),\n",
    "                      '*** Validation ***\\t',\n",
    "                      'Loss: {:.4f}'.format(validation_loss))\n",
    "        \n",
    "    train_writer.close()\n",
    "    saver.save(sess, '{}/run-{}_i{}_s{}.ckpt'.format(save_dir, now, counter, CONFIG.rnn_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T15:19:32.365275Z",
     "start_time": "2018-04-06T15:19:32.349319Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_samples(checkpoint, n_samples, primer):\n",
    "    samples = [w for w in primer.split()]\n",
    "    primer_feed = [vocab_to_int['<bos>']]\n",
    "    [primer_feed.append(vocab_to_int[word]) for word in samples]\n",
    "    model = RNNLanguageModel(out_size=CONFIG.out_size,\n",
    "                             batch_size=CONFIG.batch_size,\n",
    "                             n_steps=CONFIG.n_steps,\n",
    "                             rnn_size=CONFIG.rnn_size,\n",
    "                             rnn_size_factor=CONFIG.rnn_size_factor,\n",
    "                             rnn_layers=CONFIG.rnn_layers,\n",
    "                             learning_rate=CONFIG.learning_rate,\n",
    "                             grad_clip=CONFIG.grad_clip,\n",
    "                             embedding_size=CONFIG.embedding_size,\n",
    "                             sampling=True)\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, checkpoint)\n",
    "        new_hidden_state, new_cell_state = sess.run([model.h_init, model.C_init])\n",
    "        for i in primer_feed:\n",
    "            x = np.zeros((1,1))\n",
    "            x[0, 0] = i\n",
    "            feed_dict = {model.inputs: x,\n",
    "                         model.keep_prob: 1.0,\n",
    "                         model.h_init: new_hidden_state,\n",
    "                         model.C_init: new_cell_state}\n",
    "            best_prediction, new_hidden_state, new_cell_state = \\\n",
    "            sess.run([model.best_prediction, model.final_hidden_state,\n",
    "                      model.final_cell_state], feed_dict=feed_dict)\n",
    "            print(best_prediction.shape)\n",
    "    \n",
    "    return ' '.join(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T15:19:45.170986Z",
     "start_time": "2018-04-06T15:19:43.928843Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoints/run-18-04-06-17-13-00_i54_s512.ckpt\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Assign requires shapes of both tensors to match. lhs shape= [1,512] rhs shape= [64,512]\n\t [[Node: save/Assign_10 = Assign[T=DT_FLOAT, _class=[\"loc:@LSTM/h_init\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](LSTM/h_init, save/RestoreV2:10)]]\n\nCaused by op 'save/Assign_10', defined at:\n  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/ioloop.py\", line 760, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-140-5e590eb3a456>\", line 7, in <module>\n    output = generate_samples(checkpoint, max_generate_n, continuation_sentences[0])\n  File \"<ipython-input-139-8f420c6b4409>\", line 16, in generate_samples\n    saver = tf.train.Saver()\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1311, in __init__\n    self.build()\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1320, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1357, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 809, in _build_internal\n    restore_sequentially, reshape)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 470, in _AddRestoreOps\n    assign_ops.append(saveable.restore(saveable_tensors, shapes))\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 162, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 281, in assign\n    validate_shape=validate_shape)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 61, in assign\n    use_locking=use_locking, name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [1,512] rhs shape= [64,512]\n\t [[Node: save/Assign_10 = Assign[T=DT_FLOAT, _class=[\"loc:@LSTM/h_init\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](LSTM/h_init, save/RestoreV2:10)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [1,512] rhs shape= [64,512]\n\t [[Node: save/Assign_10 = Assign[T=DT_FLOAT, _class=[\"loc:@LSTM/h_init\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](LSTM/h_init, save/RestoreV2:10)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-140-5e590eb3a456>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Generate some text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_generate_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontinuation_sentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-139-8f420c6b4409>\u001b[0m in \u001b[0;36mgenerate_samples\u001b[0;34m(checkpoint, n_samples, primer)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mnew_hidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_cell_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC_init\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprimer_feed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m       sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1775\u001b[0;31m                {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [1,512] rhs shape= [64,512]\n\t [[Node: save/Assign_10 = Assign[T=DT_FLOAT, _class=[\"loc:@LSTM/h_init\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](LSTM/h_init, save/RestoreV2:10)]]\n\nCaused by op 'save/Assign_10', defined at:\n  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/ioloop.py\", line 760, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-140-5e590eb3a456>\", line 7, in <module>\n    output = generate_samples(checkpoint, max_generate_n, continuation_sentences[0])\n  File \"<ipython-input-139-8f420c6b4409>\", line 16, in generate_samples\n    saver = tf.train.Saver()\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1311, in __init__\n    self.build()\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1320, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1357, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 809, in _build_internal\n    restore_sequentially, reshape)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 470, in _AddRestoreOps\n    assign_ops.append(saveable.restore(saveable_tensors, shapes))\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 162, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 281, in assign\n    validate_shape=validate_shape)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 61, in assign\n    use_locking=use_locking, name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [1,512] rhs shape= [64,512]\n\t [[Node: save/Assign_10 = Assign[T=DT_FLOAT, _class=[\"loc:@LSTM/h_init\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](LSTM/h_init, save/RestoreV2:10)]]\n"
     ]
    }
   ],
   "source": [
    "# Get latest checkpoint\n",
    "checkpoint = tf.train.latest_checkpoint(save_dir)\n",
    "\n",
    "# Sentence generation limit\n",
    "max_generate_n = 20\n",
    "\n",
    "# Eventually generate some text\n",
    "output = generate_samples(checkpoint, max_generate_n, continuation_sentences[0])\n",
    "print(output)\n",
    "\n",
    "\n",
    "## Doesn't work as home-made LSTM cells don't take kindly to being reinitialized\n",
    "## with weights after reshaping to batch_size, n_steps = 1, 1.\n",
    "## Maybe needs switch back to stock LSTM cell as allowed by project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
