## Synopsis
This course presents topics in natural language processing with an emphasis on modern techniques, primarily focusing on statistical and deep learning approaches. The course provides an overview of the primary areas of research in language processing as well as a detailed exploration of the models and techniques used both in research and in commercial natural language systems.

## Reference material

- [Seminal paper: A Neural Probabilistic Language Model - Bengio et aL](http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf)
- [Blog post: Understanding LSTM Networks - Chris Olah](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)
- [Book: Deep Learning - Ian Goodfellow](http://www.deeplearningbook.org)
- [Book: Neural Networks and Deep Learning - Michael Nielsen](http://neuralnetworksanddeeplearning.com)
- [Book: Hands-on Machine Learning with Scikit-Learn and TensorFlow - Aurelien Geron](https://github.com/ageron/handson-ml)
- [Book: TensorFlow Machine Learning Cookbook - Nick McClure](https://github.com/nfmcclure/tensorflow_cookbook)
- [Documentation: TensorFlow - RNNs](https://www.tensorflow.org/tutorials/recurrent) 


## Main objective:
The objective of the course is to learn the basic concepts in the statistical processing of natural languages. The course will be project-oriented so that the students can also gain hands-on experience with state-of-the-art tools and techniques.

## License
MIT License
